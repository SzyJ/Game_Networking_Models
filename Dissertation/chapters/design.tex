\chapter{Design}

\section{Code Architecture}

Test for inline: \lstinline{test Hello;}

\section{Protocols}
During any connection that can be deployed between several processes on a machine or even different physical hardware in seperate geographical locaitons, many different protocols come into play. In this section, I will investigate the different methods of transferring data over the Internet and discuss the choices that have to be made in the design of my own protocol to allow for different clients connecting to eachother and sending data.

\subsection{Protocols in Network Communications}
Firstly, in the network layer, most commonly the IP\footnote{IP: Internet Protocol} is employed however other options such as X.25 are also available but have more niche uses. These protocols are responsible for ``packaging'' the data to be sent between two different computers identified by their IP address. The packet from the sending machine, will travel through a network of routers that will eventually lead it to the machine with the IP address of the recieving machine.

Next comes the transport layer where either UDP\footnote{UDP: User Datagram Protocol} or TCP\footnote{TCP: Transfer Control Protocol}  can be chosen, both have different properties, advantages, disadvantages, useses and both are used in game networking. The UPD protocol is a simple, connectionless protocol which will simply send a packet from one IP address to another. Since each packet sent with UDP, can take a different route through the router network, there is no guarantee that the packets will be received in the same order as they were sent in. Due to many different reasons, packet loss can occur, meaning that it also cannot be guaranteed that every packet sent with UDP will arrive at the destination at all. Despite these dissadvantages and due to the simplicity of how this protocol was designed with it's connectionless nature, it inately has a major advantage in the speed that the packets can just be sent out and forgotten about. The TCP protocol, is built upon UDP to add some important features for reliable data sharing at a cost of speen and use in real-time applications. The most important property of TCP includes the assurance that if a packet is not received by a recipient, it is requested to be resent to guarantee that every pacet that is sent, is also recieved. This also means that the packets are aranged in the same order that they were sent meaning that we can be sure that not only data will arrive at the destination, but it will arrive just as we sent it. This implementation has many obvious benefits and in most scenarios, the delay of possibly re-sending a packet if it was not received is neglegible. In real-time applications however, this is likely to be an unnecessary waste of time and resources as even id a packet is dropped and and resent, by that time, new updated information is available so resending the dropped packet is useless when a packet with new information could be sent at that time instead. Simply, old information is quickly outdated and it's more important to send new information then old, non-useful information.

The next layer of protocols is the operating system interface or library, that is called by applications needing to share data using the above protocols. With Windows, a library called ``WinSock'' is often used, however other options are also available such as enet, asio, RakNet... This is where a programmer would be able to configure which protocols to use (Like TCP or UDP, IP or X.25 amongst many other configurable options).


\subsection{Connecting the clients together}
When connecting multiple clients together, no matter what model is uesd, the session host or the server will need to know what clients will participate in this game session. A brute force solution to this would be to hard code all the information that is needed by each of the participating parties. This solution presents many flaws however. The configuration on each client would have to be configured before the first run on each new participant, as well as when a different connection pattern is wanted. While this solution would be simplest, the issues associated with connecting new clients and synchronising multiple configuration files for the syetem to work together, make this infeasable.
A common solution used in the industry is to use something known as a matchmaking server. This is a seperate server with a publicly known IP address, that would be tasked with listening in for join messages from clients and finding the best matches of players based on many different factors such as ping to the game server or player skill. The information about each client would then be passed onto the game server for the processing to start. The matchmaking idea provides many advantages including taking away the computation associated with connecting from the main gameplay server however when developing a networking solution without a central server, this defeats the point.
The most appropriate solution that I have found, combines both ideas. Firstly, there will need to be a way for the user to define what the address of the server or session host peer is. This can be done through a configuration file or getting an input from the user. With the server address known, each client can send a message to that address requesting to join a game. The client receiveing this information, would essentially act as a matchmaking server and after getting requests to join from enough players, the game could start.

\subsubsection{Design of the matchmaking server}
While the basic need for operation of the matchmaking server is slightly different for client hosted and Peer to Peer models, they will also share a lot of logic and functionality. Below is the basic flow of operation for this server.
\begin{enumerate}
\item Initialise Networking Library with predefined, known port
\item Listen for ``Join Request'' messages on the port from clients.
\item If the client is allowed to join the game, reply with ``Join Acknowledgement'' message.
\item \begin{enumerate}
  \item If the client is a P2P session host\\
     Broadcast the information about each client to each client.

  \item If the client is a CH session host\\
     Send the information about each client to the game server.
  \end{enumerate}
\end{enumerate}

I have experimented with different approaches for implementing this flow. Initially, for simplicity, the implementation consisted only of UDP messages being sent between clients. This means that only one UDP port had to be opened and therefore the same port that is used for the connection logic, would be used for the communication with the game server. After inspecting the solution, I have found that due to the nature of UDP messages, some aspects of this implementation could be volotile and leave the program in a unexpected state. If a ``Join Request'' message was not delivered, no acknowledgement message would be received and therefore a timeout waiting system would have to be implemented to resend the join message or the system would be waiting for an acknowledgement for ever. A larger issue could arise however, if the acknowledgement message is not delivered. When the server receives the join message, this client would be added to the server's memory and therefore it would be assumed that the player would be in the game. However, if the player is still waiting for an acknowledgement and the game starts, this player would not know that they are actually in the game. To solve this issue, we could introduce an acknowledgement message for the acknowledgement however as these changes are being made, we are just fixing the intrinsic unreliablity of the UDP protocol.
The obvious solution to the issues that have been encountered here, is to use the TCP protocol which exists because it has already fixed the isses addressed here.
The revised outcome of the architecture of the matchmaking server, would work in a similar way to the previous design but the TCP protocol would be used. This forces us to implement some changes to the messages that we are expecting to receive from the clients. Firstly, since the set of TCP ports and UDP ports does not overlap (i.e. TCP port 4500 is a completely different port to UDP port 4500), the connection server will need to know what UDP port has been opened by each client. This means that alongside the Join Request message, the clients will need to send the port that the game server will use to send messages. We can still use the source address of the message to know the IP address. With the TCP protocol guaraneeing that no messages are dropped, we can safely assume that each client will get all the information from the server and all clients can proceed to the game loop together. As a result of implementing a TCP server connection, this now means that each client will also have to implement logic for connecting to the server with TCP.
Overall, this is a much better solution to the original design as the code for the game logic and connection logic, is more logically organised in seperate classes.


\subsection{Main Game loop and Broadcasting}
The paper \mycite{smed2002review} discusses the topic of ``dead reckoning'' in detail. This is the idea of estimating what value is likely to be received from the server in the next packet by evaluating the previous values. In an example of an entity moving through a Virtual Environment at a constant speed in a constant direction and given that the position of this entity is being broadcasted from a game server, the game client can predict that if the previous packets have updated the position of this entity by the same amount every time, it can calculate the next value that will be received before the packet even arrives. This information can be used to interpolate the position of this entity between the packet that has just arrived and what poition it is expected to be in after the next packet arrives, thus giving the client a more smooth simulation. This also makes the smoothness of the simulation less reliant on network quality, though with low quality networking, the issue of ``rubber banding''\footnote{Rubber Banding is when a client sees an object in a simulation in a certain location but after a update of where this object should be arrives from an authority (server), this position is instantly updated to this new, correct position. From the client's point of view, this looks like the entity has teleported to the new location.} can become prevelent. Even though the implementation of such a system is out of scope of this project, the way the packets are sent from a server to the clients, can make a process like this easier.

The most common implementation for how servers broadcast data from the server to clients in AAA games, is to broadcast all necessary update data at a constant rate many times a second. If a packet is not delivered to one of the clients, there is no need to resend it since a new updated packet will be sent right after the last one. The constant rate at which the packets are sent and the idea that the same amout of time in-game time has passed between each consecutive packet that is received, makes startegies such as dead reckoning easier to implement than is the updates were sent irregularily.

\subsubsection{Update rates}
When updates are sent to clients over a network, the latency between two machines introduces the physical limitation of the lowest possible time between an action happening on one client and that action being represented on another client somewhere else on the network. This limitation cannot be broken due to the laws of physics and how the information is transmitted through the wires in a network. What makes this delay even larger, is the transmission or update rates of the data from the server to it's clients and vice-versa. When the server broadcasts data 30 times per second, it can be said that it is broadcasting at 30Hz, making the delay between each update roughly 33.33ms. This means that if the server is broadcasting at 60Hz, the delay between a client sending data and another client receiving data should be lower than if the server is broadcasting at 30Hz.

An interesting example of a potential problem that could occur is well explained in \mycite{bns2017netcode}. In some fast paced games, the update rate of the server can have a large effect on the gameplay, especially in competative scenarios. In many FPS games such as Call of Duty, the gameplay uses guns that fire many times a second. Given an example of a server broadcasing at an update rate of 10Hz and a player using a gun that fires at a rate of 600 RPM (rounds per minute), the time between a player firing two bullets and the time difference between the server sending two updates, is both 100ms. This means that each packet that the server sends will contain information about one bullet. In the same scenario, given that the player is firing a weapon with 750RPM, the delay between two bullets being fired is 80ms. This means that the server will have to send packets that contain up to two bullets. From the point of view of another player that is receiving the damage, it will seem as if one bullet from the gun could deal more damage than another bullet. This is often referenced to as ``super bullets''. This issue can be solved by increasing the update rate of the server which would also cause packet loss to be less impactful due to the amount of packets that would be received every second.


\subsubsection{Tick rates and simulation steps}
Given that the higher the update rate from the server to the clients, the better the experience for the players, why not broadcast as many messages every second as possible? The limitation to how many packets can be sent per second, is the speed of how fast the server hardware can calculate each simulation step. Baisic operation of the server can be split into two main concepts: the simulation step calculation and the tick rate.

The term tick rate refers to how many times per second, the game server will process and produce data. At a tick rate of 60Hz, the time between any two ticks would be 16.66ms meaning that the server will have a processing window of that much time to process and broadcast a simulation step. If the server manages to finish the processing of a simulation step within this window (i.e. in this example, processing took less than 16.66ms to complete), it would sleep until the next simulation step needs to be processed. A short processing time on each simulation step means that the clients receive their updates earlier which will lead to reducing the ping between players and make systems like hit registration feel more responsive in gameplay. When deciding on what tick rate is best to use for the server, it isn't always correct to set the tick rate high as possible. It is also very important to consider that in the most likely worst case scenarios the processing of each simulation step is shorter than the time between ticks. It is paramount that this processing is done within the time window as the server processing not keeping up with the tick rate, often results in inconsistencies such as failing physics or clients rubber banding therefore proving a suboptimal experiance for the clients.

In conclusion, the networking for a game should not be transmitting at a rate that is faster than the average processing time of a single simulation step. To handle this, my project should provide a configurable value of how often the simulation state should be broadcast.


\subsection{Message Structure Strategies}

\subsubsection{Data Representation}
Depening on the complexity of the game and the amount players participating in the same game instance, it is likely that a large amount of data has to be sent many times from within the main game loop. The data will be transmitted over the internet as a series of bytes and will have to be understood and put together again at the recipient's end. One of the challenges of designing a networking, real-time application, is working around the idea that for any packet sent with UDP, there is no guarantee that it will arrive.


There are many different ways that the same data can be represented and each one is carefully designed to be the most appropriate for it's use. Consider the two figures below of common ways of grouping complex data in an ``easily readable'' format; XML in Figure \ref{fig:xml-example} and JSON in Figure \ref{fig:json-example}. These example have been adapted from the article \mycite{fiedler2016packets}.

\newpage
\begin{figure}[!ht]
\begin{lstlisting}[language=xml]
<world_update world_time="0.0">
  <object id="1" class="player">
    <property name="position" value="(0,0,0)"></property>
    <property name="orientation" value="(1,0,0,0)"></property>
    <property name="velocity" value="(10,0,0)"></property>
    <property name="health" value="100"></property>
    <property name="weapon" value="110"></property>
    ... 100s more properties per-object ...
 </object>
 <object id="110" class="weapon">
   <property type="semi-automatic"></property>
   <property ammo_in_clip="8"></property>
   <property round_in_chamber="true"></property>
 </object>
 ... 1000s more objects ...
</world_update>
\end{lstlisting}

\caption{An example of a representation of world data in the XML format}
\label{fig:xml-example}
\end{figure}

\begin{figure}[!ht]
\begin{lstlisting}[language=xml]
{
  "world_time": 0.0,
  "objects": {
    1: {
      "class": "player",
      "position": "(0,0,0)",
      "orientation": "(1,0,0,0)",
      "velocity": "(10,0,0)",
      "health": 100,
      "weapon": 110
    }
    110: {
      "class": "weapon",
      "type": "semi-automatic"
      "ammo_in_clip": 8,
      "round_in_chamber": 1
    }
    // etc...
  }
}
\end{lstlisting}

\caption{An example of a representation of world data in the JSON format}
\label{fig:json-example}
\end{figure}

\newpage


\subsubsection{Detecting and Dealing with Packet Loss}
The packet information could contain a certain amount of bits that would be incremented with each simulation step\footnote{A simulation step refers to a state of values that represent the current state of a simulation. Each time the values are updated, is a new simulation step. This is often done and broadcasted several times a second in central server models.}. This counter value could loop round when a maximum value is reached as long as several simulation steps in a row have unique values. The receiver could evaluate this value when received, checking if a packet has been dropped since the last received update. Knowledge about the quality of the connection could be important information when determining how much of the simulation has to be estimated between the received updates and could also be vital information to the player when in a game demanding split-second reaction time allowing them to change their strategy with the knowledge that they may be at a dissadvantage against other players.

The article \mycite{lincroft1999internet}, documents some of the problems that were encountered in the developement of the ``X-Wing vs. TIE Fighter'' game. The team realised that dropped packets had a significant negative inpact on the game so to counter this, they have implemented a system to resend packets that didn't arrive. This system has initially fixed the issue however in some cases, even the resent packets were getting dropped which coused spikes in bandwidth usage. A solution that they have come up with is that each update packet would also contain a copy of the previous packet attached. This way, even if packet loss occurs, the simulation can stay up to date as long as two or more packets dont get dropped in a row. This solution is quite elegant as Lincroft warns that ``if you are using UDP, you shouldn’t send small packets'', as the headers of UDP packets do not get as compressed as that of TCP packets therefore its more efficient to make use of as many bytes as possible when constructing UDP packets. The solution of including the previous packet data with the current one makes use of this, otherwise wasted, space and could also act as a checksum for the data in the previous packet.

\newpage

\section{Message Code Design}
Whenever a message is received, the first two bytes will determine the type of this received message. Any unique action to be performed, should have a unique message code associated with it so that it is easy to tell what action needs to be performed after just reading the two byte identifier. If more information needs to be sent along with the message code, this information can be concatenated to the message code byte by byte. The meaning of each byte after the message code will be defined by the message code. The table \ref{table:message-codes} below, contains code descriptions of all possible messages that can be sent and received by my tool.

Understanding message code descriptions:
\begin{itemize}
\item The angle brackts (\lstinline{<>}) will represent one byte of information (e.g. \lstinline{<ID>} signifies one byte number that represents the ID).
\item The square brackets (\lstinline{[...]}) signify a sequence of undefined length with the pattern that is defined inside them (e.g. \lstinline{[<CHAR>...]} signifies that the rest of the message contains a series of charactes each represented as a char(signed byte)).
\end{itemize}
\vfill

%table:message-codes
\input{fixtures/message-code-table}
\newpage

\section{Protocol Flow}

\subsection{Establishing connection}
TODO write how code can be reused

%fig:connection_graph
\input{fixtures/connection_graph}

\newpage
\subsubsection{Interface for the client hosted model}

\begin{figure}[!h]
  \centering
  \begin{lstlisting}
      GNAT::Server* server = new GNAT::Server();

      int successful = 0;
      successful = server->startConnectionServer();
      if (!successful) {
        // Log and abort
      }
  \end{lstlisting}
  \caption{Process of opening server to client connections}
  \label{code:server_conn}
\end{figure}

\begin{figure}[!h]
  \centering
  \begin{lstlisting}
      GNAT::Client* client = new GNAT::Client();

      int successful = 0;
      // Server Details already configured
      successful = client->connectToServer();
      if (!successful) {
        // Log and abort
      }
  \end{lstlisting}
  \caption{Process of client connecting to server}
  \label{code:client_conn}
\end{figure}

\newpage
\subsubsection{Interface for the peer to peer model}

\begin{figure}[!h]
  \centering
  \begin{lstlisting}
      GNAT::Peer* peer = new GNAT::Peer();

      int successful = 0;
      successful = peer->openAsSessionHost();
      if (!successful) {
        // Log and abort
      }
  \end{lstlisting}
  \caption{Process of opening a peer up to connections from other peers}
  \label{code:peer_conn_host}
\end{figure}


\begin{figure}[!h]
  \centering
  \begin{lstlisting}
      GNAT::Peer* peer = new GNAT::Peer();

      int successful = 0;
      // Session Host Details already configured
      successful = peer->connectToSessionHost();
      if (!successful) {
        // Log and abort
      }
  \end{lstlisting}
  \caption{Process for a peer connecting to peer session host}
  \label{code:peer_conn_join}
\end{figure}

\newpage

\subsection{Client and Server communication}
TODO used in client hosted. Host client sends to server just like any other, just destination is localhost.


%fig:client_hosted_graph
\input{fixtures/client_hosted_graph}





\subsection{Peer to Peer data broadcasting}
TODO similar to client and server but sends multiple messages instead of one.
